# -*- coding: utf-8 -*-
"""CodeBERT_Training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11LCjQPkNvlnH1bKR7KG2r1ON2p0cMa4e
"""

# Install required libraries
!pip install -q transformers torch pandas scikit-learn tqdm matplotlib numpy

print("âœ… Installation complete!")
print("\nâš ï¸ IMPORTANT: Click Runtime â†’ Restart session")
print("   Then run all cells from Cell 2 onwards")

# Import libraries
import torch
import pandas as pd
import numpy as np
from torch.utils.data import Dataset, DataLoader

# âœ… UPDATED: Use AdamW from torch.optim (not transformers)
from torch.optim import AdamW

# Transformers
from transformers import (
    RobertaTokenizer,
    RobertaForSequenceClassification,
    get_linear_schedule_with_warmup
)

# Metrics
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix,
    classification_report
)

from tqdm.auto import tqdm
import warnings
warnings.filterwarnings('ignore')

# Check GPU
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"ðŸš€ Using device: {device}")
if device == 'cuda':
    print(f"   GPU: {torch.cuda.get_device_name(0)}")
    print(f"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
else:
    print("   âš ï¸ No GPU detected - training will be slower")
    print("   Go to: Runtime â†’ Change runtime type â†’ T4 GPU")

import transformers
print(f"\nðŸ“¦ Transformers version: {transformers.__version__}")

from google.colab import files
import os

# Create directories
!mkdir -p data/codebert

print("ðŸ“¤ Please upload your data files:")
print("   Required: cm1_train_code.csv, cm1_test_code.csv")
print("   Optional: pc1, jm1, kc1 files")
print("\n   Files location on your PC:")
print("   C:\\DefectPrediction\\data\\codebert\\")

uploaded = files.upload()

# Move uploaded files
for filename in uploaded.keys():
    !mv {filename} data/codebert/
    print(f"âœ… Moved {filename}")

# Verify
print("\nðŸ“‚ Files in data/codebert/:")
!ls -lh data/codebert/

class DefectDataset(Dataset):
    """Dataset class for defect prediction with CodeBERT"""

    def __init__(self, texts, labels, tokenizer, max_length=512):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = int(self.labels[idx])

        encoding = self.tokenizer(
            text,
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }

print("âœ… DefectDataset class defined")

def train_codebert(dataset_name='cm1', epochs=3, batch_size=16, learning_rate=2e-5):
    """Train CodeBERT on defect prediction"""

    print(f"\n{'='*80}")
    print(f"ðŸš€ TRAINING CODEBERT ON {dataset_name.upper()}")
    print(f"{'='*80}\n")

    # Load data
    print("ðŸ“‚ Loading data...")
    train_df = pd.read_csv(f'data/codebert/{dataset_name}_train_code.csv')
    test_df = pd.read_csv(f'data/codebert/{dataset_name}_test_code.csv')

    train_texts = train_df['code'].tolist()
    train_labels = train_df['label'].tolist()
    test_texts = test_df['code'].tolist()
    test_labels = test_df['label'].tolist()

    print(f"âœ… Data loaded!")
    print(f"   Train: {len(train_texts)} samples ({sum(train_labels)} defects = {sum(train_labels)/len(train_labels)*100:.1f}%)")
    print(f"   Test:  {len(test_texts)} samples ({sum(test_labels)} defects = {sum(test_labels)/len(test_labels)*100:.1f}%)")

    # Initialize model and tokenizer
    print("\nðŸ¤– Loading CodeBERT...")
    tokenizer = RobertaTokenizer.from_pretrained('microsoft/codebert-base')
    model = RobertaForSequenceClassification.from_pretrained(
        'microsoft/codebert-base',
        num_labels=2
    )
    model.to(device)
    print(f"âœ… Model loaded! Parameters: {sum(p.numel() for p in model.parameters()):,}")

    # Create datasets and dataloaders
    print(f"\nðŸ“¦ Creating dataloaders (batch_size={batch_size})...")
    train_dataset = DefectDataset(train_texts, train_labels, tokenizer)
    test_dataset = DefectDataset(test_texts, test_labels, tokenizer)

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    print(f"âœ… Dataloaders ready!")

    # Setup optimizer (âœ… Using torch.optim.AdamW)
    optimizer = AdamW(model.parameters(), lr=learning_rate)

    # Setup scheduler
    total_steps = len(train_loader) * epochs
    scheduler = get_linear_schedule_with_warmup(
        optimizer,
        num_warmup_steps=0,
        num_training_steps=total_steps
    )

    # Training loop
    print(f"\n{'='*80}")
    print(f"ðŸŽ“ STARTING TRAINING")
    print(f"{'='*80}\n")

    best_f1 = 0
    history = {'train_loss': [], 'val_metrics': []}

    for epoch in range(epochs):
        print(f"\n{'='*80}")
        print(f"EPOCH {epoch + 1}/{epochs}")
        print(f"{'='*80}")

        # Training
        model.train()
        total_loss = 0
        progress_bar = tqdm(train_loader, desc=f"Training Epoch {epoch+1}")

        for batch in progress_bar:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            total_loss += loss.item()

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            scheduler.step()

            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})

        avg_loss = total_loss / len(train_loader)
        history['train_loss'].append(avg_loss)
        print(f"\nâœ… Epoch {epoch + 1} completed! Avg loss: {avg_loss:.4f}")

        # Evaluation
        model.eval()
        predictions = []
        true_labels = []
        probs = []

        print("\nðŸ“Š Evaluating...")
        with torch.no_grad():
            for batch in tqdm(test_loader, desc="Evaluating"):
                input_ids = batch['input_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)
                labels = batch['labels'].to(device)

                outputs = model(input_ids=input_ids, attention_mask=attention_mask)
                logits = outputs.logits
                preds = torch.argmax(logits, dim=1)
                probs_batch = torch.softmax(logits, dim=1)[:, 1]

                predictions.extend(preds.cpu().numpy())
                true_labels.extend(labels.cpu().numpy())
                probs.extend(probs_batch.cpu().numpy())

        # Calculate metrics
        accuracy = accuracy_score(true_labels, predictions)
        precision = precision_score(true_labels, predictions, zero_division=0)
        recall = recall_score(true_labels, predictions, zero_division=0)
        f1 = f1_score(true_labels, predictions, zero_division=0)
        auc_roc = roc_auc_score(true_labels, probs)

        metrics = {
            'epoch': epoch + 1,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'auc_roc': auc_roc
        }
        history['val_metrics'].append(metrics)

        print(f"\nðŸ“Š Epoch {epoch + 1} Results:")
        print(f"   Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"   Precision: {precision:.4f} ({precision*100:.2f}%)")
        print(f"   Recall:    {recall:.4f} ({recall*100:.2f}%)")
        print(f"   F1-Score:  {f1:.4f} ({f1*100:.2f}%)")
        print(f"   AUC-ROC:   {auc_roc:.4f} ({auc_roc*100:.2f}%)")

        # Save best model
        if f1 > best_f1:
            best_f1 = f1
            !mkdir -p models/codebert_{dataset_name}
            model.save_pretrained(f'models/codebert_{dataset_name}')
            tokenizer.save_pretrained(f'models/codebert_{dataset_name}')
            print(f"\nðŸ’¾ New best F1! Model saved.")

    # Final report
    print(f"\n{'='*80}")
    print(f"ðŸŽ‰ TRAINING COMPLETED!")
    print(f"{'='*80}")
    print(f"Best F1-Score: {best_f1:.4f}")

    # Confusion Matrix
    cm = confusion_matrix(true_labels, predictions)
    print(f"\nðŸ“‹ FINAL CONFUSION MATRIX:")
    print(f"                Predicted")
    print(f"              Non-Defect  Defect")
    print(f"Actual Non-D    {cm[0,0]:>6}     {cm[0,1]:>6}")
    print(f"       Defect   {cm[1,0]:>6}     {cm[1,1]:>6}")

    print(f"\nðŸ“„ CLASSIFICATION REPORT:")
    print(classification_report(true_labels, predictions,
                               target_names=['Non-Defective', 'Defective']))

    return history, metrics

print("âœ… Training function ready")

# Run training
results_cm1, final_metrics_cm1 = train_codebert('cm1', epochs=3, batch_size=16)

# Save results
results_df = pd.DataFrame([{
    'Model': 'CodeBERT',
    'Dataset': 'CM1',
    'Accuracy': f"{final_metrics_cm1['accuracy']:.4f}",
    'Precision': f"{final_metrics_cm1['precision']:.4f}",
    'Recall': f"{final_metrics_cm1['recall']:.4f}",
    'F1-Score': f"{final_metrics_cm1['f1_score']:.4f}",
    'AUC-ROC': f"{final_metrics_cm1['auc_roc']:.4f}"
}])

results_df.to_csv('cm1_codebert_results.csv', index=False)
print("\nâœ… Results saved to cm1_codebert_results.csv")
print("\nðŸ“Š FINAL RESULTS TABLE:")
print(results_df.to_string(index=False))

import pandas as pd

# Prepare PC1 results
results_pc1_df = pd.DataFrame([{
    'Model': 'CodeBERT',
    'Dataset': 'PC1',
    'Accuracy': f"{final_metrics_pc1['accuracy']:.4f}",
    'Precision': f"{final_metrics_pc1['precision']:.4f}",
    'Recall': f"{final_metrics_pc1['recall']:.4f}",
    'F1-Score': f"{final_metrics_pc1['f1_score']:.4f}",
    'AUC-ROC': f"{final_metrics_pc1['auc_roc']:.4f}"
}])
results_pc1_df.to_csv('pc1_codebert_results.csv', index=False)
print("\nâœ… Results saved to pc1_codebert_results.csv")

# Prepare KC1 results
results_kc1_df = pd.DataFrame([{
    'Model': 'CodeBERT',
    'Dataset': 'KC1',
    'Accuracy': f"{final_metrics_kc1['accuracy']:.4f}",
    'Precision': f"{final_metrics_kc1['precision']:.4f}",
    'Recall': f"{final_metrics_kc1['recall']:.4f}",
    'F1-Score': f"{final_metrics_kc1['f1_score']:.4f}",
    'AUC-ROC': f"{final_metrics_kc1['auc_roc']:.4f}"
}])
results_kc1_df.to_csv('kc1_codebert_results.csv', index=False)
print("\nâœ… Results saved to kc1_codebert_results.csv")

# Prepare JM1 results
results_jm1_df = pd.DataFrame([{
    'Model': 'CodeBERT',
    'Dataset': 'JM1',
    'Accuracy': f"{final_metrics_jm1['accuracy']:.4f}",
    'Precision': f"{final_metrics_jm1['precision']:.4f}",
    'Recall': f"{final_metrics_jm1['recall']:.4f}",
    'F1-Score': f"{final_metrics_jm1['f1_score']:.4f}",
    'AUC-ROC': f"{final_metrics_jm1['auc_roc']:.4f}"
}])
results_jm1_df.to_csv('jm1_codebert_results.csv', index=False)
print("\nâœ… Results saved to jm1_codebert_results.csv")

# Display combined results
all_results_df = pd.concat([results_df, results_pc1_df, results_kc1_df, results_jm1_df], ignore_index=True)
print("\nðŸ“Š ALL FINAL RESULTS TABLE:")
display(all_results_df)

# Uncomment to train on PC1, KC1, or JM1
# Make sure you've uploaded those files first!

# PC1 (if uploaded)
results_pc1, final_metrics_pc1 = train_codebert('pc1', epochs=3, batch_size=16)

# KC1 (if uploaded)
results_kc1, final_metrics_kc1 = train_codebert('kc1', epochs=3, batch_size=16)

# JM1 (largest - use smaller batch size)
results_jm1, final_metrics_jm1 = train_codebert('jm1', epochs=3, batch_size=8)

print("âœ… Optional training cells")